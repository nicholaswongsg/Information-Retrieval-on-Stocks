{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b732b03",
   "metadata": {},
   "source": [
    "# General Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d63ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97495573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Classification/NER_with_ensemble_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5118041",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab2efd",
   "metadata": {},
   "source": [
    "### Unique Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f812919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pysolr\n",
    "\n",
    "# # Connect to Solr\n",
    "# solr = pysolr.Solr('http://localhost:8983/solr/reddit_core', always_commit=True, timeout=10)\n",
    "\n",
    "# # Search for all documents\n",
    "# results = solr.search('*:*', rows=2147483647)\n",
    "\n",
    "# df = pd.DataFrame(results)\n",
    "# for column in df.columns:\n",
    "#     # Check if the column contains lists\n",
    "#     if df[column].apply(lambda x: isinstance(x, list)).any():\n",
    "#         # Extract the single value from each list\n",
    "#         df[column] = df[column].apply(lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75debc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subreddits: ['applestocks' 'microsoft' 'NVDA_Stock' 'wallstreetbets' 'stockmarket'\n",
      " 'stocks']\n"
     ]
    }
   ],
   "source": [
    "subss = df['subreddit'].unique()\n",
    "print(\"Unique subreddits:\", subss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc30367",
   "metadata": {},
   "source": [
    "## Time filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5430ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest: 1740806007\n",
      "Earliest: 1608636755\n"
     ]
    }
   ],
   "source": [
    "time = df['created_utc'].unique()\n",
    "max_time = max(time)\n",
    "min_time = min(time)\n",
    "print(\"Latest:\", max_time)\n",
    "print(\"Earliest:\", min_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b4e0b",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca304aa",
   "metadata": {},
   "source": [
    "### Num Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf56f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 11465\n"
     ]
    }
   ],
   "source": [
    "num_records = len(df)\n",
    "print(\"Number of records:\", num_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e21f7a",
   "metadata": {},
   "source": [
    "### Num Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384dd929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 551229\n"
     ]
    }
   ],
   "source": [
    "all_text = ' '.join(df['ner_text_cleaned'].astype(str))\n",
    "words = all_text.split()\n",
    "num_words = len(words)\n",
    "print(\"Number of words:\", num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b81b2",
   "metadata": {},
   "source": [
    "### Num Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbf97bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 28605\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(words)\n",
    "num_unique_words = len(unique_words)\n",
    "print(\"Number of unique words:\", num_unique_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
