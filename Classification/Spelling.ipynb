{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/99zh55td5557wrk09bgvss_w0000gn/T/ipykernel_2001/516262375.py:17: DtypeWarning: Columns (7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean: samsung galaxy?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# A dictionary of known synonyms or forced corrections\n",
    "SYNONYMS = {\n",
    "    \"appl\": \"apple\",\n",
    "    \"appin\": \"apple\",\n",
    "    \"aplin\": \"apple\",\n",
    "    \"appln\": \"apple\",\n",
    "    \"aapl\": \"apple\",\n",
    "    \"nvda\": \"nvidia\",\n",
    "    # Add as many forced mappings as you need\n",
    "}\n",
    "\n",
    "def load_domain_dictionary(csv_file_path, text_column='ner_text_cleaned'):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    texts = df[text_column].dropna()\n",
    "    \n",
    "    all_words = []\n",
    "    for line in texts:\n",
    "        line_clean = re.sub(r'[^\\w\\s]', '', line.lower())\n",
    "        words = line_clean.split()\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    return all_words\n",
    "\n",
    "def build_spellchecker(csv_file_path):\n",
    "    # Increase distance to 3 for more flexible corrections (optional)\n",
    "    spell = SpellChecker(distance=3)\n",
    "\n",
    "    domain_words = load_domain_dictionary(csv_file_path)\n",
    "    spell.word_frequency.load_words(domain_words)\n",
    "\n",
    "    # Boost stock-related words; large frequency ensures they outrank common English words\n",
    "    stock_names = [\"apple\", \"tesla\", \"nvidia\", \"amazon\", \"google\", \"meta\", \"microsoft\"]\n",
    "    for name in stock_names:\n",
    "        spell.word_frequency.add(name, 1000000)  # Very high frequency to overshadow common words\n",
    "    \n",
    "    return spell\n",
    "\n",
    "def correct_query(spell, user_query):\n",
    "    query_clean = re.sub(r'[^\\w\\s]', '', user_query.lower())\n",
    "    query_words = query_clean.split()\n",
    "    \n",
    "    corrected_words = []\n",
    "    for w in query_words:\n",
    "        # 1) Force known synonyms first\n",
    "        if w in SYNONYMS:\n",
    "            corrected_words.append(SYNONYMS[w])\n",
    "        # 2) If recognized, keep as-is\n",
    "        elif w in spell:\n",
    "            corrected_words.append(w)\n",
    "        else:\n",
    "            # 3) Otherwise, use spell.correction\n",
    "            correction = spell.correction(w)\n",
    "            corrected_words.append(correction if correction else w)\n",
    "    \n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def search_engine_demo():\n",
    "    csv_file_path = \"NER_with_sentiment.csv\"\n",
    "    spell = build_spellchecker(csv_file_path)\n",
    "    \n",
    "    user_query = input(\"Enter search query: \")\n",
    "    suggestion = correct_query(spell, user_query)\n",
    "    \n",
    "    if suggestion != user_query.lower():\n",
    "        print(f\"Did you mean: {suggestion}?\")\n",
    "    else:\n",
    "        print(\"Your query looks good!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_engine_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
